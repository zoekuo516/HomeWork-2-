{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdMJjedhdi/aeSxUZ8TNaU"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Text generation**"
      ],
      "metadata": {
        "id": "pza8HRkONuLb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GRugKBmlNlZ5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def reweight_distribution(original_distribution, temperature=0.5):\n",
        "    distribution = np.log(original_distribution) / temperature\n",
        "    distribution = np.exp(distribution)\n",
        "    return distribution / np.sum(distribution)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_yw2tMgNm-9",
        "outputId": "3b6d5727-b112-484b-e1cb-03342bade923"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-12 10:30:24--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  12.8MB/s    in 23s     \n",
            "\n",
            "2022-12-12 10:30:47 (3.56 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "dataset = keras.utils.text_dataset_from_directory(\n",
        "    directory=\"aclImdb\", label_mode=None, batch_size=256)\n",
        "dataset = dataset.map(lambda x: tf.strings.regex_replace(x, \"<br />\", \" \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOt2bIhBNm8y",
        "outputId": "6ac58e8e-a6f9-4c93-aed9-227a402dc6d4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100006 files belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "sequence_length = 100\n",
        "vocab_size = 15000\n",
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "text_vectorization.adapt(dataset)"
      ],
      "metadata": {
        "id": "uEsgM6LzNm6k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_lm_dataset(text_batch):\n",
        "    vectorized_sequences = text_vectorization(text_batch)\n",
        "    x = vectorized_sequences[:, :-1]\n",
        "    y = vectorized_sequences[:, 1:]\n",
        "    return x, y\n",
        "\n",
        "lm_dataset = dataset.map(prepare_lm_dataset, num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "-slqDczcNm4F"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(PositionalEmbedding, self).get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "          num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "          num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(TransformerDecoder, self).get_config()\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim,\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1),\n",
        "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
        "        return tf.tile(mask, mult)\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(\n",
        "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs,\n",
        "            value=inputs,\n",
        "            key=inputs,\n",
        "            attention_mask=causal_mask)\n",
        "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=attention_output_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        attention_output_2 = self.layernorm_2(\n",
        "            attention_output_1 + attention_output_2)\n",
        "        proj_output = self.dense_proj(attention_output_2)\n",
        "        return self.layernorm_3(attention_output_2 + proj_output)"
      ],
      "metadata": {
        "id": "5IhL9MM6NmzB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 2\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, x)\n",
        "outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"rmsprop\")"
      ],
      "metadata": {
        "id": "AVb88OmuNmuj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "tokens_index = dict(enumerate(text_vectorization.get_vocabulary()))\n",
        "\n",
        "def sample_next(predictions, temperature=1.0):\n",
        "    predictions = np.asarray(predictions).astype(\"float64\")\n",
        "    predictions = np.log(predictions) / temperature\n",
        "    exp_preds = np.exp(predictions)\n",
        "    predictions = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, predictions, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "class TextGenerator(keras.callbacks.Callback):\n",
        "    def __init__(self,\n",
        "                 prompt,\n",
        "                 generate_length,\n",
        "                 model_input_length,\n",
        "                 temperatures=(1.,),\n",
        "                 print_freq=1):\n",
        "        self.prompt = prompt\n",
        "        self.generate_length = generate_length\n",
        "        self.model_input_length = model_input_length\n",
        "        self.temperatures = temperatures\n",
        "        self.print_freq = print_freq\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.print_freq != 0:\n",
        "            return\n",
        "        for temperature in self.temperatures:\n",
        "            print(\"== Generating with temperature\", temperature)\n",
        "            sentence = self.prompt\n",
        "            for i in range(self.generate_length):\n",
        "                tokenized_sentence = text_vectorization([sentence])\n",
        "                predictions = self.model(tokenized_sentence)\n",
        "                next_token = sample_next(predictions[0, i, :])\n",
        "                sampled_token = tokens_index[next_token]\n",
        "                sentence += \" \" + sampled_token\n",
        "            print(sentence)\n",
        "\n",
        "prompt = \"This movie\"\n",
        "text_gen_callback = TextGenerator(\n",
        "    prompt,\n",
        "    generate_length=50,\n",
        "    model_input_length=sequence_length,\n",
        "    temperatures=(0.2, 0.5, 0.7, 1., 1.5))"
      ],
      "metadata": {
        "id": "cC1vk0dENmsN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(lm_dataset, epochs=10, callbacks=[text_gen_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtYnFrt0Nmpv",
        "outputId": "5a43ea37-9314-48d9-b472-7d38c5b7def1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 5.3561== Generating with temperature 0.2\n",
            "This movie is is quite a to cheap watch movie believability most moments forgettable use when credit it for fans that over all the the mgm audience was plays a himself great from actors that is is great one for but more not than film anything he behind factory so being ill\n",
            "== Generating with temperature 0.5\n",
            "This movie film had [UNK] a in crime when then i by 1995 figuring and out kills what somehow happened bullock to made [UNK] it his isnt name there and anyway likable [UNK] but that its she predecessor stinks and for getting whatever annoying it heads started every over word this ridiculous\n",
            "== Generating with temperature 0.7\n",
            "This movie film takes is some dreadful kind that of could when find start it with just the so same far story better that and those japan scenes in and that a annoying digital message candyman about kane society mildred however cartoons as arent they creepy try sure to conclusion make only\n",
            "== Generating with temperature 1.0\n",
            "This movie is was only a about waste twenty of years my ago comments and special i quality dont cant let mind way original for they me call wrong the overall plot the it dialogue is was so well very this dull silly and especially plausible well for well trademark  original\n",
            "== Generating with temperature 1.5\n",
            "This movie is was a heart nice of to humor get while a that chance movie dream with of no view events that such sometimes been tacky 20000 and made slight it i strikes was me i on found it myself by to taking dvd different but nasty its or another that\n",
            "391/391 [==============================] - 178s 437ms/step - loss: 5.3561\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.8155== Generating with temperature 0.2\n",
            "This movie show really was [UNK] expecting that to [UNK] say [UNK] this i [UNK] watched was the watching worst [UNK] movie movie on you the i next was creature wanted features to to everything see that what go i around would it fall because to they the [UNK] utter would nonsense\n",
            "== Generating with temperature 0.5\n",
            "This movie is is lovely about i a males happy looking i forward laughed a a while kid at with blockbuster a i paying was bravo able i to watched make it this stupid movie after with a a story low that budget this and is the not first a [UNK] good\n",
            "== Generating with temperature 0.7\n",
            "This movie film purpose is is terrible so the bad dog only we sounds have to the be awful so but bad after thing this i idea just about have it been since an trying soft [UNK] porn stop flick to it be the sure kind what of has [UNK] nothing [UNK]\n",
            "== Generating with temperature 1.0\n",
            "This movie is has annoying it biggest turned problem me of wrong me i with cant this even movie like is that a bad thousand 80s movies horror that movies figures either and putting the this ratings alone and the its heck still of no the one movie his in character the\n",
            "== Generating with temperature 1.5\n",
            "This movie is is a the great kind drama of but typical it example is dog avoid a no film way when any a movement [UNK] or this flow one before is i far do decline watch throughout and the better end sets but the even whole with movie pure writing stupidity\n",
            "391/391 [==============================] - 171s 436ms/step - loss: 4.8155\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.5917== Generating with temperature 0.2\n",
            "This movie succeeded was best made i by rank any it way on through video the if long [UNK] sound mother of is the only only everybody reason else that i they seen bore the the script current was status the cant worst look film like i a have must read write\n",
            "== Generating with temperature 0.5\n",
            "This movie takes begins place with in voters the being actual the film only manages really the offers very of much [UNK] worthwhile of but acting is cinematography absolutely and classic its and remarkable just and what easy starts [UNK] with in a the humorous production climax values is the set acting\n",
            "== Generating with temperature 0.7\n",
            "This movie movie was is sick just so a [UNK] give [UNK] your [UNK] laugh the made main me character cry away because from the all mary of [UNK] his movies [UNK] creates love the sickly characters first seem time to by start this and is execution the of script fact given\n",
            "== Generating with temperature 1.0\n",
            "This movie is may a [UNK] 90 mouse or de two force are tierney very to engaging protest leads the [UNK] two casual attempts alan at despite a his terrific secret uninspiring [UNK] story [UNK] stars [UNK] from stylish england [UNK] robards [UNK] and scientist bryan realizes brown his and main chris\n",
            "== Generating with temperature 1.5\n",
            "This movie movie uk covers for a everyone christmas to in make an movies independent i review think a this great is movie not just good might and deliver i that love i it saw you it liked before very until funny just about because five basically main watching characters this get\n",
            "391/391 [==============================] - 171s 437ms/step - loss: 4.5917\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.4643== Generating with temperature 0.2\n",
            "This movie is could a anyone possible across do the they horizon have they been must searching owed for out that the the alliance economic was [UNK] burned evil the down enemy the towards bank earth after to the death frank and love his they seller also both briefly of used these\n",
            "== Generating with temperature 0.5\n",
            "This movie could is be of funny the its talking special plot effects unfunny get dialogue whipped and and [UNK] [UNK] up the ham songs men has in been the motivated world by boarding or schools pink were kurt what russell could recap be of convincing job the working nice guy luxury\n",
            "== Generating with temperature 0.7\n",
            "This movie movie was was ever a cool horrible everything movie about in even day abandoned [UNK] making resident why room would crashes have [UNK] a girls twist leg at lesbian the debbie end  of the movie could be better to survive this movie would they have made each other too\n",
            "== Generating with temperature 1.0\n",
            "This movie aint was just definitely plain worth bad watching acting because isnt it even too forever much was originality i either would held have back been am searching from for the this main movie character was does probably anyone have do seen better it if is you scary feel police all\n",
            "== Generating with temperature 1.5\n",
            "This movie is had completely a blank spoof by of ida horror lupino fans [UNK] ask 3 him lone who eye supposedly judge died [UNK] until capitalize driven on effort what of to czech be republic said pictures in of sydney the or deep the remains costumes amusing were because [UNK] from\n",
            "391/391 [==============================] - 171s 437ms/step - loss: 4.4643\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.3758== Generating with temperature 0.2\n",
            "This movie didnt could work have with billy promise crystal of story crooked and cops another screwed then the they is for obviously those ludicrous who acting really themselves cant and do try anything to dimwitted survive in enough the this first isnt is really in the a same [UNK] manner only\n",
            "== Generating with temperature 0.5\n",
            "This movie movie looks revolves like around a working group class of in people [UNK] from this the is [UNK] the cannon reason atmosphere the is plot to is be pain bad except the for main the character fight is in left a alone tense is during one the lead movie by\n",
            "== Generating with temperature 0.7\n",
            "This movie is was a made case doesnt for really any historical sort lines of could everything be in comical it [UNK] was all [UNK] about by is [UNK] organized truth in is the that way they back made and a the holocaust film that made made me of want natural to\n",
            "== Generating with temperature 1.0\n",
            "This movie is has about such michael yet [UNK] hes is a reduced legendary to bmovie this production is it awful that and it hurts is his hilarious people [UNK] for into chocolate music or in metal what [UNK] that mean is where caused the the beatles inevitable the 60s result as\n",
            "== Generating with temperature 1.5\n",
            "This movie is is not a the perfectly movie [UNK] compared whatever to you the would kungfu expect is for to a be half entertainment and this is more one and of better the films script were has actually really been none updated to today everything it is turns gratuitous clean and\n",
            "391/391 [==============================] - 171s 436ms/step - loss: 4.3758\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.3091== Generating with temperature 0.2\n",
            "This movie is is terrible not and just not a even big remotely surprise good that about it that has it had can three be plot overlooked a it psychiatric impresses ward me its a revel total [UNK] of into concrete her fate leg is is wrongly among [UNK] the pieces [UNK]\n",
            "== Generating with temperature 0.5\n",
            "This movie movie is is whilst even one at of [UNK] the it most is does tortured it and has continues it over tries the to actions be of realistic a the message story that all can committed find however out awful about photo drugs of anna a bruce new willis kid\n",
            "== Generating with temperature 0.7\n",
            "This movie film demonstrates made the watching impact as of humorous the it movie would stars have from been the happy beginning gilmore but must cannot be be compared repeated to worst a hollywood total [UNK] inability that to side see actors them perform pulling very their badly own to are tell\n",
            "== Generating with temperature 1.0\n",
            "This movie movie was needs terrible all acting over horrendous done editing mistakes are coupled pointless with and plot sequences lines of were soul [UNK] or unrealistic purpose looks or like budget that that the the actors writers are truly supposed embarrassed to to be see there no is story no in\n",
            "== Generating with temperature 1.5\n",
            "This movie is has ridiculous would plot have everyone been that away should for never their being that said of the an swedish alien company in is and probably i very highly interested anticipated in film watching my the mistake stars lets of face what it makes is up the for first\n",
            "391/391 [==============================] - 171s 435ms/step - loss: 4.3091\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.2554== Generating with temperature 0.2\n",
            "This movie movie [UNK] is just simply out pathetic of with [UNK] it [UNK] would [UNK] much and more [UNK] [UNK] agreed star [UNK] performance [UNK] they is had driving its water the [UNK] [UNK] about [UNK] the that [UNK] they of had four to teen first [UNK] do [UNK] the before\n",
            "== Generating with temperature 0.5\n",
            "This movie film meant takes very elements fast from forward the to great an extent action of desert the hunted settings as overall this it is has an a strong best story screenplay about and two the little main girls characters a getting bit stabbed the in plot a with way some\n",
            "== Generating with temperature 0.7\n",
            "This movie is is terrible just it like do a it bitch has and to sensual people by in namely a absent die spirit only and in criticisms series people her may behaviors very the well film be moves done along so with you you the then acting with as the as\n",
            "== Generating with temperature 1.0\n",
            "This movie is is that a i bad would [UNK] love it to but languages have certainly seen but the it whole was area so dont [UNK] expect and much overthetop action dialog comedy panic there and is where no is one [UNK] of arrived them [UNK] especially by sam the steiner\n",
            "== Generating with temperature 1.5\n",
            "This movie is is an sad brilliant example [UNK] of you what probably you the would best think actor now bruce ive rambo seen ii in 1994 the is other equivalent version of without vengeance his at goes the to same the end exact and a only bomb shorter that than has\n",
            "391/391 [==============================] - 171s 437ms/step - loss: 4.2554\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.2110== Generating with temperature 0.2\n",
            "This movie movie is took my no 19 [UNK] year to old see school by kathleen all turner seasons and 4 roger really [UNK] excited is when a richard sexy pryor woman is hardened a by distinctly incompetent bad coworkers peter stooges falk steven is carey a pretending genius to role be\n",
            "== Generating with temperature 0.5\n",
            "This movie movie is sucked pure in cross no between point jokes i and love government old not delta i delta want force you to into watch the causing [UNK] him watching back his [UNK] gun player battle a at [UNK] so chris youll i like only this kruger could nominated screw\n",
            "== Generating with temperature 0.7\n",
            "This movie oneman has star no trek idea that its i a think bit comedy it to does a have nice a production couple values of to ever an show unattractive with kid absolutely adult simplistic lines crooks of who [UNK] are toward trapped parody in monster a suits clown can mix\n",
            "== Generating with temperature 1.0\n",
            "This movie is is undoubtedly superior [UNK] recommendation that that it details stands the as test one its sided still as boldly a wb matter film of gate end this up is making voiced the up audience movie with influences lovely that music emerged score many a years huge ago t there\n",
            "== Generating with temperature 1.5\n",
            "This movie movie is that about bad aimed reviews fact at pi all local of comedy us based not on knowing the bram casting [UNK] of certainly elizabeth give bates everyone most a of behaviors us which who has are recently seemingly living regular the people reviews that boll seem does to\n",
            "391/391 [==============================] - 171s 437ms/step - loss: 4.2110\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.1737== Generating with temperature 0.2\n",
            "This movie is is funny not and just is does everything not aniston really is is in that [UNK] said is the what only gets gas me is directions that meant some to money put and it a proves pure it schlock is i good could about have an had [UNK] experience\n",
            "== Generating with temperature 0.5\n",
            "This movie is somehow a hilarious superbly comedy made with from a an script action which drama they or needed its to participation be cagney given in that a it real is crossing written the in line their of cowrote the and script acted because by of a the director same of\n",
            "== Generating with temperature 0.7\n",
            "This movie rather tries is to hard be to smart [UNK] the people plot who at give the this idea film might is be not the even best funny it harrison also is has a a long great haired director girl who but throws that them is out a in bit the\n",
            "== Generating with temperature 1.0\n",
            "This movie is was quality not it wasted is harsh one funny of person my why time i and dislike i such dont fun understand them why the this hell is are never so even bad though that i theyll cannot be explain long the problems same is problems that sound is\n",
            "== Generating with temperature 1.5\n",
            "This movie is is incredible [UNK] my in only this 70 movie it the is story a of big a mistake man and performed why it he is is so such much a larger good role role and in he this deserves doesnt him aim credit very to well him to once\n",
            "391/391 [==============================] - 171s 437ms/step - loss: 4.1737\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - ETA: 0s - loss: 4.1415== Generating with temperature 0.2\n",
            "This movie western is arguably divided one into for three those star ideas fool on when whilst they seeing are them asking they its have too to convicted improvise guilty is an one acquired whos cell attitudes [UNK] with with the [UNK] phantom from of the the other plot allied twists why\n",
            "== Generating with temperature 0.5\n",
            "This movie is was not just awful horrendous although and some kudos supplies a [UNK] van talented heflin performance like she shemp is  all okay this but is eventually basically going the to plays play out it like starts a shortly lady touch schemes with 15 her things like get for\n",
            "== Generating with temperature 0.7\n",
            "This movie is was in lousy a camera video where of is the the clumsy home housewife [UNK] who of developed the characters acting severely and [UNK] production these gave standard new disaster insight to into us stupid as and one boring wonders 25 whether year they old had smart the lines\n",
            "== Generating with temperature 1.0\n",
            "This movie was was different another and waste boring of predictable time ridden the characters acting were was poor cringe the unconvincing narrator fraternity was all better over then supporting the the whole main time characters were relation wasted confused on pretentious a bodies travel and only the throne actors one associated\n",
            "== Generating with temperature 1.5\n",
            "This movie movie was is just confusing crappy and in its a misery story the line movies is to dumber be and used the to entitled fast uncle as jesse his wanted brother [UNK] slap they in try the to face decide combs who had goes combined away wild running golf backwards\n",
            "391/391 [==============================] - 171s 437ms/step - loss: 4.1415\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0f7f4fdaf0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}
